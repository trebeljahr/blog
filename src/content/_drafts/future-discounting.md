---
title: "Reverse Future Discounting"
excerpt: "Why taking into account how the future will change, has to strongly influence our decision making."
cover: "/assets/blog/tall-buildings.jpg"
date: "2022-16-22"
author:
  name: Rico Trebeljahr
  picture: "/assets/blog/profile.jpeg" 
---

When making decisions there is something important to keep in mind. Namely, how stable you think the future is. There is this constant pull, between doing things that feel pleasurable now, and doing things that will yield higher results later. We're essentially playing a game, where just like in a Prisoners Dilemma Game we need to keep in mind how long the future is going to last. Depending on how long that is, our choices have to be effected by this. 

A friend of mine has a little post it note on his mirror to remind him to do the things that are important in life. It says something like this:

> If today were the last day of your life, would you do what you are doing today? 

I have a problem with that post it note. Namely, the answer to that question should almost always be no. If I know for sure, that I am going to die today, the only thing I am probably going to do is to heavily indulge in pleasurable things. The extreme of that would probably be to try out all kind of harmful drugs, like heroine. However I really don't think that that is a good way of living overall. Because there is a future to keep track of and plan for and foregoing pleasure in the short run, for pleasure or some other benefit in the long run is a game that is very important to optimize. 

For me there is a specific connection here – namely I have two things that I can't really do at the same time: 

Work on something meaningful **and** travel. If I travel, I don't work, and if I work I don't travel. Working is preparing something for the future. It's in some way or another foregoing pleasure now and building a better future down the road. Travel on the other hand is enjoying the present to it's utmost. It's living in the present, spending money, taking life to it's fullest. The problem is, traveling is not sustainable and the world is (hopefully) not going to end tomorrow. Hence I need to plan for a mix of both. But... 

When is the world going to end?

The answer to this question that we come up with and believe to be true should have huge implications on how we make our decisions. If the future is something that is inherently different in a major way, that the calculus of "preparing" for the future is significantly affected, then this should influence our decision making. 

There are two scenarios that fall into this category that are on the top of my mind, right now. 

1. Armageddon (aka Nuclear War)
2. AI making human workers obsolete

If either of them happens in the near future, working now to achieve something in the near future is meaningless and *not worth it*, if compared to having only fun. 

It's like insisting that you'd rather start building a house on the last day of your life instead of taking heroine or some other drug all day long. What the fuck are you going to need the house for? It's a heroic move for sure, but a stupid one. From a raw optimization game point of view, you should do whatever makes you the happiest, because your choices of the day won't matter in the long run at all.

The argument that you'd start building this house for posterity (say your children), and that that's why it matters even though you are dead the next day, by the way, doesn't count either. Sorry. 

You are still thinking in terms of a future that according to the "rules" of the game as we have defined them is not going to exist. Namely in the case of nuclear war, all houses on Earth will soon be uninhabited and your children, just like you, will be dead. In the AI case, building a house doesn't matter either, because AI robots could build the house for free, or in case of an AI takeoff, the whole concept of "house" would probably be pretty meaningless. 

I don't like that fact that somehow this framework of thought feels very nihilistic. 

It's like our choices don't matter that much in the end, which is true, but can be self-defeating and very depressing. I'd rather think positively about the future. 

If looking at this through the Kantian imperative (i.e. what would happen if everybody were to think and act that way?) we would clearly see that acting this idea out would be morally reprehensible. 

If nobody is building the future, and everybody taking heroine, then we'll never get to the future we envisioned in the first place. The future, that made us act in that way, is not going to exist, because us acting that way... Especially option 2 needs humans actively working towards it, otherwise it doesn't happen. The first one to, but it's much more likely to happen on "it's own" or by accident with the systems that are already in place right now. 

Following from all of this comes, what I would call a decision matrix, composed of 2 questions. In my mind, it's not really a hard "yes/no" matrix, but more of a gradual change and I am thinking of how it can be codified into some form of "algebra" but for now the idea of it being a matrix is good enough. 

The two questions are:

Is the world going to end in the short term? Next 5 years?

What did you do for those five years? 

Following from that we get 4 results: 

/Sketch here: 

                 prepared for the future			NOT prepared for the future
NOT different               1.             |           4.
              –––––––––––––––––––––––––––– | ––––––––––––––––––––––––––
different                   3.​					    |           2. 

the question now becomes: How would you rank these outcomes?

To me the worst would be to have not prepared for the future and then having a "not different" future. The amount of pain and regret this would cause is something I wouldn't want in my life. Just imagine yourself in that future, without money, always looking back at "the good old times", struggling to make a living and scrape by. 

Next for me would come having worked and prepared for a future, when there is no future that's going to exist in that way and your preparation becomes moot. Again, the pain and regret that this would cause, in terms of "oh how much fun I could have had" instead of toiling away, building something that is now meaningless, would be horrible.

The last two scenarios missing, to me, are the harder ones to rank. It's when we have worked to prepare for a future AND the future we prepared for is the one we thought it's going to be vs. NOT being prepared, but it doesn't matter anymore, because there is not future. 

Of course I would rather live in a future, so if there was nuclear war in the no future scenario, it's pretty easy to decide. But in the AI scenario, it becomes much harder. 

I think, personally, that it's better to have been hard at work, preparing for a future, when that future also exists in the way envisioned and the preparation was worth it. In that case, enjoyment, in much larger quantities, can be derived from it and it was sustainable as well. 

There is another thing to keep in mind here. Our idea of "is there going to be a future", is always only an estimate and thereby we have to weight our matrix above by the likelyhood of our belief being wrong. If we are really certain about there being no future, the effect of this stronger belief should be reflected in our decision making as well. The whole idea should be weighted by the amount of certainty on our beliefs. 

Another thing that should effect the decision is the timeframe that we think this is going to happen over. If you believe that the future is significantly different enough to not warrant working anymore, how soon is that going to happen? Tomorrow? In a year's time? In 5 years time? Or is it still far away, say 20 or more years?

Depending on that timeframe, the future might be uncertain, but there is enough of it, that is still certain, that we still have to prepare for that part of it. If taking all of this in combination we get to something quite interesting. A spectrum of choices we could make, ranging from taking heroine – Sorry for the obsession about heroine, I just think it really captures the example of "something really bad for you, that also, very likely feels extraordinarily good"... – and other short term actions to full on trying to innovate, founding companies and making the world a better place through better technology etc. 

The degree of difference as well as the pain/pleasure derived from this should also effect our decision making. If thinking about all of this, it becomes much much harder to actually decide. But in a way, that calculation can be done, subconsciously. By taking notice of all of these things, and then simply projecting yourself, mentally, into that world, and thinking, hmm. How would that feel. Nudging around these variables, changing the mental projection of how that world (and our position in it) are going to feel like... This idea by the way is something that our brains do all the time anyways to think about the future and how to weigh actions in the now against the future... And it is described more in [The Righteous Mind by Jonathan Haidt](/booknotes/the-righteous-mind) and [The Enigma of Reason by Dan Sperber](/booknotes/the-enigma-of-reason). Remember though, that in doing so our brain is biased towards the present and the now. Being able to correct for that bias, and override short term goals for longer term goals is something that makes humans relatively unique. Being able to reverse future discounting and actually think about the effects that these ideas have on how we want to and *should* behave is a bit like magic. 

There are also human biases at play. Namely, how easy is it, as humans, to entirely do one or the other? In a way, we are always a bit shortsighted and have a bias (known as future discounting) towards the future. It means that our brains don't regard pleasure in the future as highly as pleasure now. We discount the future. 

Another thing to keep in mind here: There is a degree of alignment and a way of preparing for the future that is different for each of the possible sets of futures.
Especially in the AI (or any "advanced" technology scenario) we could certainly influence that future and how it's going to look like to some degree and our choices would make a difference. How we act, then, would translate into a different future, and would, potentially, align the future we actually live in, with the one that we planned for. Because through our actions we steered the future in the right way. 

So, if we actively help building the future, we can influence, to some degree where things are headed and therefore improve our odds of getting there. This is something that needs to be taken into account in the calculus of future discounting.

