---
title: "Reverse Future Discounting"
subtitle: "How you think about the future should affect your decision making"
excerpt: "A friend of mine has a little post-it note on his mirror to remind him to do the things that are important in life. It says: 'If today were the last day of your life, would you do what you are doing today?' I have a real problem with that post-it note."
cover: "/assets/blog/tall-buildings.jpg"
date: "2022-16-22"
author:
  name: Rico Trebeljahr
  picture: "/assets/blog/profile.jpeg" 
—

My friend Marc has a little Post-it note on his mirror to remind him to do the things that are important in life. It says: 

> If this were the last day of your life, would you do what you are doing today?

I have a real problem with that Post-it note:

Why?

Because the answer to that question should be *no*.

When I know for sure that I am going to die today, then the only thing I am going to do is to heavily indulge in pleasurable things.

Things like, spending time with my family, having sex, or, on the extreme end, trying out harmful drugs like heroin. The point is, most of us would want to spend our last moments not working – but in blissful hedonistic pleasure.

But, if you aren't going to die tomorrow, spending your time *only* doing those things is unsustainable. Because there *is* a future to keep track of and plan for.

When making decisions we have to keep the future and how stable we think it's going to be in mind. If we do, there is a constant pull between doing things that feel pleasurable now and doing things that will yield higher results *later*.

We're playing a game of tradeoffs, where we need to keep in mind how long the future is going to last to decide optimally. Depending on how long we think that is, our choices have to be adjusted. If I think I am going to die tomorrow, my choice of what I do should be different than if I expect to live another year. And they should be different again if I expect to live another 10, 20, or 30 years. 


Trading pleasure in the short run for pleasure in the long run, is the core idea behind most self-help advice out there. It is encapsulated in quotes like this:

> Hard choices, easy life. Easy choices, hard life.

– Jerzy Gregorek

What's missing from that quote is the duration of "how long your life is going to last". Because there is truth to it, that the easy choices make your life harder in the long run, because they accrue debt, things that you have to fix later, things that will haunt you later. But when you die tomorrow, this concern of the long run is eliminated, it's not as important anymore.


Hence when making decisions we have to keep in mind how long the future is going to last. Depending on our best guess of how it is going to look like we can decide to minimize regret. However, there is another side to this, because the future is not a "yes" or "no" kind of thing.

It is a continuum of different possibilities, all with lots of uncertainty attached to them. And especially today, with technology advancing extremely rapidly, you might think that the future is going to rapidly change as well, which makes planning hard, or even impossible.
And that too, should be taken into account when deciding. 

But the question remains: How should we plan our lives in light of an uncertain future? 


Work on something meaningful, making sacrifices for it.  
Living "in the moment", hedonistically striving for pleasure. 

To me, these manifest in two things, work vs. travel. If I travel, I don't work, and if I work I don't travel. Work is preparing something for the future. It's foregoing pleasure now to build a better future. Travel on the other hand is living in the present, spending money, and taking life to its fullest. However, full-time traveling is not sustainable in the long run.

Both lose their beauty if done at the same time and they can't be combined, I can switch between them, but never do both at the same time. 

Hopefully, the world is not going to end tomorrow. Which means that there is a future to worry about. There is one big unknown here though: When is the world, as we know it, going to end? How long is the future we are planning for going to exist? How we answer this, has huge implications for how we should make our decisions.

If the future is inherently different in a major way, and the calculus of "preparing" for the future is significantly affected, then this should influence our decision-making.

Two scenarios fall into this category: 

1. [Armageddon](https://www.julian.com/feature/armageddon) (aka Nuclear War)
2. [AI making human workers obsolete](/posts/open-ai-codex)

If either of them happens soon (on a timescale of 5-10 years), working now to achieve something in the far future is meaningless and *not worth it*, if compared to having only fun.

It's like insisting that you'd rather start building a house on the last day of your life instead of taking heroin or some other drug all day long. What the fuck do you need the house for? It's a heroic move for sure, but a stupid one. You should just do whatever makes you the happiest, right now because your choices of the day won't matter in the long run. Nothing would have consequences beyond this day, so taking heroin, which is normally a very bad choice would suddenly make a lot of sense. 

The argument that you'd start building this house for posterity and that that's why it matters even though you are dead the next day, by the way, doesn't count either. Sorry.

You are still thinking in terms of a future that, according to the "rules" of the game as we have defined them, is not going to exist. Namely in the case of nuclear war, all houses on Earth (including the one you started building) will soon be uninhabited. And your children, just like you, will be dead.

In the AI case, building a house doesn't matter either, because AI robots could build the house for free, or in the case of an AI takeoff, the whole concept of "house" would likely be somewhat meaningless.

I don't like that this framework feels nihilistic, but it's fundamentally right to think about life choices in that way. 

## Does the future even matter?

From this point of view, it seems like our choices don't matter in the end. This idea can be self-defeating, dark, and depressing. I'd rather think positively about the future. But that our choices don't matter is not true, on the contrary, they matter quite a lot because they have the power to change both how we live right now and how the future is going to look. 

But you might say: "Ultimately nothing *really* matters because eventually the universe is going to end and so all human achievement is utterly meaningless in the long run". Ok. Well, you are probably right. But I still like to think of us as ["The Beginning of Infinity"](/booknotes/the-beginning-of-infinity). So until the end of the universe, humanity could be on an endless quest to figure out the rules for how this universe works. And who knows, maybe we'll find out that the universe is going to end in the way that we think we know now, after all. Or we might find ways to bend or even break the rules. Or 42. The point is, there is plenty of time and plenty of unknown physics we could not even dream of right now. And that might very well change the rules in the grand scheme of things. 

So the future, and our actions to influence it, potentially matter a great deal. Maybe even more than we think right now. However, if we know that the future is going to be different enough so that we can't plan for and influence it, then having fun is the better way. Because why bother improving something that other people fix already? 

If we look at this idea through the Kantian imperative (i.e. what would happen if everybody were to think and act that way?) we would see that this would be morally reprehensible. It's a classic tragedy of the commons.

If nobody is building the future, and everybody is taking heroin, then we'll never get to the future we envisioned in the first place. The "future" we imagined, that made us act in that way, is not going to exist because of us acting that way... Especially the option of technological progress (coupled with AI) needs humans actively working towards it. Otherwise, it doesn't happen. 

## The Decision Matrix

Following this, we get a decision matrix, composed of two questions. In my mind, it's not a hard "yes/no" matrix, but more of a gradual change and I am thinking of how it can be codified. But for now, the idea of it being a yes/no matrix is good enough to think about it.

The two questions are:

Is the world going to end or change dramatically in the short term? Let's say in the next 5 years.

What did you do during those five years? 

Following these questions we get 4 results:

/Sketch here: 

                 prepared for the future			NOT prepared for the future
NOT different               1.             |           4.
              –––––––––––––––––––––––––––– | ––––––––––––––––––––––––––
different                   3.​					    |           2. 

the question now becomes: How would you rank these outcomes?

To me, the worst would be to have not prepared for the future and then have a "not different" future. The amount of pain and regret this would cause is something I wouldn't want in my life. Just imagine yourself in that future, without resources, always looking back at "the good old times", struggling to make a living and scraping by. To me, this sounds like the most horrible version and the one I would regret living in the most.

Next for me would come having worked and prepared for a future, when no future's going to exist in that way. So that your preparation was unnecessary. Again, the pain and regret that this would cause, in terms of "oh how much fun I could have had" instead of toiling away, building something that is now meaningless, would be horrible.

The last two scenarios, to me, are the harder ones to rank. It's when we have worked to prepare for a future AND the future we prepared for is the one we thought it was going to be vs. NOT being prepared, but it doesn't matter anymore, because there is no future like that we have envisioned and the future "takes care of itself" *somehow*. 

Of course, I would rather live, so if there was nuclear war in the no-future scenario, it's pretty easy to decide. But in the AI scenario, it becomes much harder. 

Maybe it's better to have been hard at work, preparing for a future, when that future also exists in the way envisioned and the preparation was worth it. In that case, enjoyment, in much larger quantities, can be derived from that future and my choices were sustainable as well. 

## Nuances and Spectrums

There is another thing to keep in mind here. The answer to "How is the future going to be?", is only ever an estimate and thereby we have to weigh our questions from above by the likelihood of our belief of being wrong in our guess about what the future is going to be like.

If we are certain that there is no future that we can have a positive impact on, then the effect of this stronger belief should be reflected in our decision-making as well. The whole idea should be weighted by the amount of certainty in our beliefs.

Another thing that should affect the decision-making is the timeframe. If you believe that the future is significantly different enough not to warrant working anymore, how soon is that going to happen? Tomorrow? In a year? In 5 years? Or is it still far away, say 20, 100 years, or even more?

The longer the timeframe, the more uncertain we should be of the future. But on the flip side, the longer the timeframe the more time there will be to steer the future's course to something better. 

A spectrum of choices we could make, ranging from taking heroin – Sorry for the obsession about heroin, I just think it captures the example of "something really bad for you in the long run, that also very likely feels extraordinarily good now"... – and other short term actions to full on trying to innovate, founding companies, and making the world a better place through better technology, etc. 

The degree of difference, as well as the pain/pleasure derived from this, should also affect our decision-making. Thinking about all of this makes it harder to decide. But in a way, that calculation can be done, subconsciously.

By taking notice of all of these things, and then projecting yourself, mentally, into that world, and thinking, hmm. How would that feel? Nudging around these variables, changing the mental projection of how that world (and your position in it) would feel like... 

This is something that our brains do all the time already. We don't think about the future and how to weigh pleasure now against pleasure in the future. Instead, our brains project how our bodies would feel in a certain situation and then judge whether that would be pleasurable or not... This idea, of taking feeling as a subconscious guide to "good" vs. "bad" actions are described more in [The Righteous Mind by Jonathan Haidt](/booknotes/the-righteous-mind) and [The Enigma of Reason by Dan Sperber](/booknotes/the-enigma-of-reason). 

There are also human biases at play. Namely, how easy is it for humans to entirely do one or the other? In a way, we are always a bit shortsighted and have a present bias(https://en.wikipedia.org/wiki/Present_bias). This means we are always discounting the future. We want things now, rather than in the future, and would rather have a little of something now, than more of it later. We also remember past experiences differently from how we experienced them at the time. Some things are fun at the moment, but we don't remember them so fondly in hindsight.

Being able to correct for that bias, and to override short-term goals for longer-term goals, is something that makes humans unique. We are able to reverse our own bias towards discounting the future. We have the ability to *reverse future discounting*. We can choose to forego pleasure now, to build something epic later, and this has led us to live pretty awesome lives right now compared to just a few hundred years ago. 

Another thing to keep in mind here: There is a degree of alignment and a way of preparing for the future that is different for each of the possible sets of futures.

Especially in AI (or any "advanced" technology scenario), we could certainly influence that future and how it's going to look. And our choices would make a difference. How we act, directly translates into what future we end up in. The future we get to inhabit can be linked to the one that we wish for through our actions. We can steer the future, by building it. 

If we actively help build the future, we can influence to some degree where things are headed. And therefore improve our odds of getting there. This is something we need to take into account in the calculus of reversing future discounting. 

Overall, thinking in this way helps clarify choices in life quite a bit. Specifically, enjoy your life while you can, and build something meaningful if you think it's going to matter over the course of your life. And who knows… maybe you can mix both or make work feel so good that the distinction between short-term pleasure and long-term gain is no longer necessary because they are the same thing? 

## Summary 

Humans have a bias towards pleasure right now. However, we have the option to rationally reverse that bias. And we should do so because the future is important and how we act matters a lot.

But, there is a risk. Focusing on the future can be overdone. We should not unnecessarily endure hardships to prepare for a future, that might take care of itself. Because if there is no future, then preparing for one doesn't make sense. In those cases, it would be smarter to give in to our human bias, because our actions towards the future wouldn't matter as much. 

Finding the balance here is the key, knowing when to value the future, higher than the present and when not to do so. 
